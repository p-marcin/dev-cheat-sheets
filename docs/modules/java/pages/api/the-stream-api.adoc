= The Stream API

== Map/Filter/Reduce algorithm implementation in JDK

Steps of the *Map/Filter/Reduce algorithm*:

Map::
*Changes the type* of the data, *does not change the number* of elements. The mapping step *respects the order* of your objects

Filter::
*Does not change the type* of the data, *changes the number* of elements. You may end up with no data

Reduce::
Produces *a result*

If we want to create *an efficient implementation* of the Map/Filter/Reduce algorithm, it *should not duplicate any data*. It should work in the same way, performance wise, as the *iterative pattern*. Map/Filter/Reduce algorithm implemented by the Collection API would cause *duplication of the data* (storing the data in an intermediate structure)

The Stream API::
Implementation of the Map/Filter/Reduce algorithm that *does not duplicate any data* and that *does not create any load on the CPU or memory*

IMPORTANT: Stream by definition is *an empty object* - it does not carry any kind of data

NOTE: Every time you call a method on a Stream that returns another Stream, it is going to be *a new Stream object*

Difference between the Stream API and iterative approach is that in the Stream API we *describe the computation and not how this computation should be conducted*. This is none of my business, this is the business of the API

Reduce method triggers *the computation of the elements*, and those elements are going to be taken *one-by-one, first mapped, then filtered and computed if they pass the filtering step*. Using Streams is about *creating pipelines of operations*.

Intermediate operation (Map/Filter)::
Operation that creates a Stream (it does not do anything, it does not process any data)

Terminal operation (Reduce)::
Operation that produces a result (it will trigger the computation of the elements)

IMPORTANT: If you have a pattern using a Stream that *does not end up with a Terminal operation*, your pattern is not going to process any data. *It will be useless code*

CAUTION: You are *not allowed* to process *the same Stream twice*. This is why it is completely useless to create intermittent variables to store the Streams. *You should inline it*

== The Stream API

The Stream API gives you **4** interfaces:

* https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html[`âšª *Stream<T>*`^] - a sequence of elements supporting sequential and parallel aggregate operations
+
[cols="1,3,4a"]
|===
| Modifier and Type | Method | Description

| `<R> Stream<R>`
| `map(Function<? super T,? extends R> mapper)`
| Returns a stream consisting of the results of applying the given function to the elements of this stream.

| `IntStream`
| `mapToInt(ToIntFunction<? super T> mapper)`
| Returns an https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/IntStream.html[`âšª IntStream`^] consisting of the results of applying the given function to the elements of this stream.

| `<R> Stream<R>`
| `flatMap(Function<? super T,? extends Stream<? extends R>> mapper)`
| Returns a stream consisting of the results of replacing each element of this stream with the contents of a mapped stream produced by applying the provided mapping function to each element

[,java]
----
long count = cities.stream() // <1>
    .flatMap(city -> city.getPeople().stream()) // <2>
    .count(); // <3>
----
<1> 3 cities
<2> With 3 people each
<3> Returns 9

| `Stream<T>`
| `filter(Predicate<? super T> predicate)`
| Returns a stream consisting of the elements of this stream that match the given predicate.

| `Optional<T>`
| `reduce(BinaryOperator<T> accumulator)`
| Performs a reduction on the elements of this stream, using an associative accumulation function, and returns an https://docs.oracle.com/en/java/javase/21/docs//api/java.base/java/util/Optional.html[`ğŸ”´ Optional<T>`^] describing the reduced value, if any. See <<_reducing_data_to_compute_statistics>>.

| `T`
| `reduce(T identity, BinaryOperator<T> accumulator)`
| Performs a reduction on the elements of this stream, using the provided identity value and an associative accumulation function, and returns the reduced value. See <<_reducing_data_to_compute_statistics>>.

| `<R, A> R`
| `collect(Collector<? super T,A,R> collector)`
| Performs a mutable reduction operation on the elements of this stream using a https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Collector.html[`âšª Collector<T,A,R>`^]. See <<_the_collectors_api>> and <<_collecting_data_from_streams_to_create_listssetsmaps>>.

| `Stream<T>`
| `distinct()`
| Returns a stream consisting of the distinct elements (according to https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/lang/Object.html#equals(java.lang.Object)[`Object#equals(Object)`^]) of this stream.

| `Stream<T>`
| `sorted()`
| Returns a stream consisting of the elements of this stream, sorted according to natural order.

| `long`
| `count()`
| Returns the count of elements in this stream.

| `Optional<T>`
| `min(Comparator<? super T> comparator)`
| Returns the minimum element of this stream according to the provided `âšª Comparator<T>`.

| `Optional<T>`
| `max(Comparator<? super T> comparator)`
| Returns the maximum element of this stream according to the provided `âšª Comparator<T>`.

| `Object[]`
| `toArray()`
| Returns an array containing the elements of this stream.

| `<A> A[]`
| `toArray(IntFunction<A[]> generator)`
| Returns an array containing the elements of this stream, using the provided generator function to allocate the returned array, as well as any additional arrays that might be required for a partitioned execution or for resizing. For example `toArray(String[]::new)` will return `String[]`.

|===

* https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/IntStream.html[`âšª *IntStream*`^] - `int` primitive specialization of `âšª Stream<T>`
+
[cols="1,3,4a"]
|===
| Modifier and Type | Method | Description

| `OptionalInt`
| `min()`
| Returns an https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/OptionalInt.html[`ğŸ”´ OptionalInt`^] describing the minimum element of this stream, or an empty optional if this stream is empty.

| `OptionalInt`
| `max()`
| Returns an https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/OptionalInt.html[`ğŸ”´ OptionalInt`^] describing the maximum element of this stream, or an empty optional if this stream is empty.

| `OptionalDouble`
| `average()`
| Returns an https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/OptionalDouble.html[`ğŸ”´ OptionalDouble`^] describing the arithmetic mean of elements of this stream, or an empty optional if this stream is empty.

| `int`
| `sum()`
| Returns the sum of elements in this stream.

| `IntSummaryStatistics`
| `summaryStatistics()`
| Returns an https://docs.oracle.com/en/java/javase/21/docs//api/java.base/java/util/IntSummaryStatistics.html[`ğŸŸ¢ IntSummaryStatistics`^] describing various summary data about the elements of this stream.

|===

* https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/LongStream.html[`âšª *LongStream*`^] - `long` primitive specialization of `âšª Stream<T>`. It has similar methods to `âšª IntStream`
* https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/DoubleStream.html[`âšª *DoubleStream*`^] - `double` primitive specialization of `âšª Stream<T>`. It has similar methods to `âšª IntStream`

[#_the_collectors_api]
== The Collectors API

https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Collectors.html[`ğŸ”´ Collectors`^] - implementations of https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Collector.html[`âšª Collector<T,A,R>`^] that implement various useful reduction operations, such as accumulating elements into collections, summarizing elements according to various criteria, etc.

Type parameters of `âšª Collector<T,A,R>`:

* `T` - the type of input elements to the reduction operation
* `A` - the mutable accumulation type of the reduction operation (often hidden as an implementation detail)
* `R` - the result type of the reduction operation

[cols="1,3,4a"]
|===
| Modifier and Type | Method | Description

| `static <T> Collector<T,?,List<T>>`
| `toList()`
| Returns a `âšª Collector<T,A,R>` that accumulates the input elements into a new https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/List.html[`âšª List<T>`^], in encounter order.

| `static <T> Collector<T,?,List<T>>`
| `toUnmodifiableList()`
| Returns a `âšª Collector<T,A,R>` that accumulates the input elements into an unmodifiable `âšª List<T>`, in encounter order.

| `static <T> Collector<T,?,Set<T>>`
| `toSet()`
| Returns a `âšª Collector<T,A,R>` that accumulates the input elements into a new `âšª Set<T>`.

| `static <T> Collector<T,?,Set<T>>`
| `toUnmodifiableSet()`
| Returns a `âšª Collector<T,A,R>` that accumulates the input elements into an unmodifiable `âšª Set<T>`.

| `static <T, C extends Collection<T>> Collector<T,?,C>`
| `toCollection(Supplier<C> collectionFactory)`
| Returns a `âšª Collector<T,A,R>` that accumulates the input elements into a new `âšª Collection<T>`, in encounter order. For example `toCollection(MyCollection::new)` will return `ğŸŸ¢ MyCollection`.

| `static Collector<CharSequence,?,String>`
| `joining()`
| Returns a `âšª Collector<T,A,R>` that concatenates the input elements into a `ğŸ”´ String`, in encounter order. The string won't be delimited.

| `static Collector<CharSequence,?,String>`
| `joining(CharSequence delimiter)`
| Returns a `âšª Collector<T,A,R>` that concatenates the input elements, separated by the specified delimiter, in encounter order.

| `static Collector<CharSequence,?,String>`
| `joining(CharSequence delimiter, CharSequence prefix, CharSequence suffix)`
| Returns a `âšª Collector<T,A,R>` that concatenates the input elements, separated by the specified delimiter, with the specified prefix and suffix, in encounter order.

| `static <T, K> Collector<T,?,Map<K,List<T>>>`
| `groupingBy(Function<? super T,? extends K> classifier)`
| Returns a `âšª Collector<T,A,R>` implementing a "group by" operation on input elements of type `T`, grouping elements according to a classification function, and returning the results in a `âšª Map`.

| `static <T, K, A, D> Collector<T,?,Map<K,D>>`
| `groupingBy(Function<? super T,? extends K> classifier, Collector<? super T,A,D> downstream)`
| Returns a `âšª Collector<T,A,R>` implementing a cascaded "group by" operation on input elements of type `T`, grouping elements according to a classification function, and then performing a reduction operation on the values associated with a given key using the specified downstream `âšª Collector<T,A,R>`.

| `static <T> Collector<T,?,Long>`
| `counting()`
| Returns a `âšª Collector<T,A,R>` accepting elements of type `T` that counts the number of input elements.

| `static <T> Collector<T,?,Integer>`
| `summingInt(ToIntFunction<? super T> mapper)`
| Returns a `âšª Collector<T,A,R>` that produces the sum of an integer-valued function applied to the input elements. For example `summingInt(City::getPopulation)` will return population of all cities.

|===

== Building a Stream from Data in Memory

* Creating a Stream from *Arrays*:
** ğŸ”´ https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/Arrays.html#stream(T%5B%5D)[`Arrays#stream(T[+]+ array)`^] - returns a sequential `Stream<T>` with the specified array as its source
** âšª https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html#of(T%2E%2E%2E)[`Stream<T>#of(T... values)`^] - returns a sequential ordered stream whose elements are the specified values
+
[,java]
----
Stream<String> streamOfStrings = Stream.<String>of("abcd", "efgh");
----
* Creating a Stream from *a Text File*:
** ğŸ”´ https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/nio/file/Files.html#lines(java.nio.file.Path)[`Files#lines(Path path)`^] - read all lines from a file as a `Stream<String>`
+
[,java]
----
Path path = Path.of("src/main/resources/first-names.txt"); // <1>
try (Stream<String> lines = Files.lines(path)) {
    long count = lines.count(); // <2>
} catch (IOException e) {
    e.printStackTrace();
}
----
<1> File with 200 lines
<2> Returns 200
* Creating a Stream from *a RegEx*:
** ğŸ”´ https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/regex/Pattern.html[`Pattern#splitAsStream(CharSequence input)`^] - creates a `Stream<String>` from the given input sequence around matches of this pattern.
+
[,java]
----
String sentence = "the quick brown fox jumps over the lazy dog";

// <1>
String[] words = sentence.split(" ");
long count1 = Arrays.stream(words).count(); // <3>

// <2>
long count2 = Pattern.compile(" ").splitAsStream(sentence).count(); // <3>
----
<1> *Bad Practice:* we create an array and store it in memory
<2> *Best Practice:* we do not create an array when we create a `âšª Stream<T>` from `ğŸ”´ Pattern`
<3> Returns 9
* Creating an `âšª IntStream` *(Stream of ASCII Codes)* from a String:
** ğŸ”´ https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/lang/String.html[`String#chars()`^] - Returns an `âšª IntStream` of int zero-extending the char values from this sequence.
+
[,java]
----
String sentence = "the quick brown fox jumps over the lazy dog";
sentence.chars()
    .mapToObj(codePoint -> Character.toString(codePoint)) // <1>
    .filter(letter -> !letter.equals(" "))
    .distinct().sorted().forEach(System.out::print);
----
<1> Converts `âšª IntStream` to `âšª Stream<String>`
* *Selecting* elements of a Stream:
+
[,java]
----
IntStream.range(0, 30)
    .skip(10) // <1>
    .limit(10) // <2>
    .forEach(index -> System.out.print(index + " ")); // <3>
----
<1> Skip first 10 elements
<2> Take next 10 elements after skip
<3> Prints "10 11 12 13 14 15 16 17 18 19"
* *Closing* a `âšª Stream<T>` with a `âšª Predicate<? super T>`:
** https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html#takeWhile(java.util.function.Predicate)[`takeWhile`^] - consume elements of the `âšª Stream<T>` until `âšª Predicate<? super T>` is *true*
+
[,java]
----
Stream.<Class<?>>iterate(ArrayList.class, c -> c.getSuperclass())
    .takeWhile(c -> c != null)
    .forEach(System.out::println);
// Prints:
class java.util.ArrayList
class java.util.AbstractList
class java.util.AbstractCollection
class java.lang.Object
----
** https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html#dropWhile(java.util.function.Predicate)[`dropWhile`^] - consume remaining elements of the `âšª Stream<T>` after `âšª Predicate<? super T>` becomes *false*
+
[,java]
----
Stream.<Class<?>>iterate(ArrayList.class, c -> c.getSuperclass())
    .dropWhile(c -> !c.equals(AbstractCollection.class))
    .forEach(System.out::println);
// Prints
class java.util.AbstractCollection
class java.lang.Object
null
Exception in thread "main" java.lang.NullPointerException: Cannot invoke "java.lang.Class.getSuperclass()" because "c" is null
----

== Converting a For Loop to a Stream

* The following:
+
[,java]
----
int sum = 0;
int count = 0;
for (Person person : people) {
    if (person.getAge() > 20) {
        count++;
        sum += person.getAge();
    }
}
double average = 0d;
if (count > 0) {
    average = sum / count;
}
----
can be converted into:
+
[,java]
----
double average = people.stream()
    .mapToInt(Person::getAge)
    .filter(age -> age > 20)
    .average().orElseThrow();
----
* The Stream API *always computes one thing*. Never sacrifice the *readability* of your code to the *performance*. The performance here is measured in *nanoseconds*:
+
[,java]
----
double totalAmount = 0;
int frequentRenterPoints = 0;
String statement = composeHeader();
for (Rental rental : rentals) {
    totalAmount += computeRentalAmount(rental);
    frequentRenterPoints += getFrequentRenterPoints(rental);
    statement += computeStatementLine(rental);
}
statement += composeFooter(totalAmount, frequentRenterPoints);
----
can be converted into:
+
[,java]
----
double totalAmount = rentals.stream()
    .mapToDouble(this::computeRentalAmount)
    .sum();
int frequentRenterPoints = rentals.stream()
    .mapToInt(this::getFrequentRenterPoints)
    .sum();
String statement = composeHeader();
statement += rentals.stream()
    .map(this::computeStatementLine)
    .collect(Collectors.joining());
statement += composeFooter(totalAmount, frequentRenterPoints);
----

TIP: Forget about *processing your data in one pass* (unless you are doing *an SQL request*). Most of the time when you have a for loop or when you have a `âšª Stream<T>`, the JVM will optimize that for you and get rid of your for loop, get rid of your iteration, and you will have a zero pass of your data, just inline code, *extremely performant, and extremely efficient*. See https://colinchjava.github.io/2023-10-25/08-46-54-893363-fine-grained-optimizations-provided-by-jit-compiler-in-java/[Fine-grained optimizations provided by JIT Compiler in Java^]

[#_reducing_data_to_compute_statistics]
== Reducing Data to compute Statistics

https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html#reduce(java.lang.Object,java.util.function.BinaryOperator)[`âšª Stream<T>#reduce(T identity, BinaryOperator<T> accumulator)`^] adds the Identity Element before the elements of the `âšª Stream<T>`.

* If you have an empty `âšª Stream<T>`, it will *return Identity Element*
* If you have only one element in the `âšª Stream<T>`, it will *return the reduction of the Identity Element and this only element*:
+
image:java:the-stream-api/stream-reduce.png[,500]

CAUTION: Some reduction operations *do not have any Identity Element* (in case for the https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/IntStream.html#min()[`âšª IntStream#min()`^], the https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/IntStream.html#max()[`âšª IntStream#max()`^], the https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/IntStream.html#average()[`âšª IntStream#average()`^] and https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html#reduce(java.util.function.BinaryOperator)[`âšª Stream<T>#reduce(BinaryOperator<T> accumulator)`^].

CAUTION: `ğŸ”´ Optional<T>` are used by the Stream API, because in cases where we have an empty `âšª Stream<T>` without any Identity Element *we don't have any result*.

[#_collecting_data_from_streams_to_create_listssetsmaps]
== Collecting Data from Streams to create Lists/Sets/Maps

Collector::
Complex object *used to reduce a Stream*. Can be used to gather data in *collections* and *maps* - it is called as *reduction in a "mutable container"* or *mutable reduction*

Downstream Collector::
Collector that is passed to https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Collectors.html#groupingBy(java.util.function.Function,java.util.stream.Collector)[`ğŸ”´ Collectors#groupingBy(Function<? super T,? extends K> classifier, Collector<? super T,A,D> downstream)`^] which is applied to the streaming of the list of values

The Collector API::
Uses the https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html#collect(java.util.stream.Collector)[`Stream#collect(Collector<? super T,A,R> collector)`^] that takes `âšª Collector<T,A,R>` implementation as a parameter:
+
* Use https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Collectors.html[`ğŸ”´ Collectors`^] class and its factory methods
* You can create your own collectors, but it is complex and tricky

[,java]
----
// Bad Practice
List<Person> people = new ArrayList<>();
List<Person> peopleFromNewYork = new ArrayList<>(); // <1>
people.stream()
    .filter(p -> p.getCity().equals("New York"))
    .forEach(p -> peopleFromNewYork.add(p));

// Best Practice
List<Person> people = new ArrayList<>();
List<Person> peopleFromNewYork = people.stream()
    .filter(p -> p.getCity().equals("New York"))
    .collect(Collectors.toList()); // <2>
----
<1> Creating a `âšª List<E>` to store the result
<2> Using `âšª Collector<T,A,R>` to store the result in `âšª List<E>`

== Parallelism in the Stream API

You can make a regular `âšª Stream<T>` a parallel `âšª Stream<T>` *in two ways*:

* by calling https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/BaseStream.html#parallel()[`âšª BaseStream<T,S extends BaseStream<T,S>>#parallel()`^] method on existing `âšª Stream<T>`
* by calling https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/Collection.html#parallelStream()[`âšª Collection<E>#parallelStream()`] method instead of calling https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/Collection.html#stream()[`âšª Collection<E>#stream()`]

These intermediate operations are going to set *a special bit* in the `âšª Stream<T>` that will *trigger the computations in parallel when you call your terminal operation*.

After terminal operation is called, the `âšª Stream<T>` implementation will check this special bit:

* *if it is set to 1*, then the computation will happen *in parallel* and will trigger special algorithms for that
* *otherwise* it will be processed *sequentially*

[TIP]
====
https://openjdk.org/projects/code-tools/jmh/[*JMH (Java Microbenchmark Harness)*^]::
Standard tool to measure the performances of your Java code. You can find JMH Template project https://github.com/p-marcin/jmh-template[here^].
====

TIP: To proper measure the performance of a Java application you first need to run it *a certain number of times (warmup)*, because within JVM there is a special just-in-time C2 compiler that can optimize your code a lot.

== Getting the best performance gains from parallel `âšª Stream<T>`

[IMPORTANT]
====
Beware, you'll have **two unboxing** and **one boxing** here (which have an impact on performance!):

[,java]
----
Integer j = 3;
Integer l = 4;
Integer k = j + l;
----

Similarly, iterating and doing some operation over `int[]` will be *much faster* than over `ğŸ”´ Integer[]` (due to unboxing and boxing).
====

Each physical core of the CPU access *two levels of cache*, which are *private*:

* L1 - the first level of cache (*small, very fast*)
* L2 - the second level of cache (*bigger, little slower*).

L3 - the third level of cache is *shared by all physical cores* (*bigger, little slower than L2*).

Main memory lives *outside the CPU* and is accessed *much slower* than L3:

image::java:the-stream-api/cpu-caches.png[,450]

How does a core of CPU access data from the main memory?::
This data will have to be *transferred* first to the L3 cache, then to the L2 cache, and then to the L1 cache *before being available* by this core of CPU.

The memory is *not read in a random way*. If a core of CPU wants to access just an `int`, it will transfer *line of memory*, not just an `int`. The memory is *transferred line by line* from the main memory to the different levels of cache. Each line is typically *64* bytes (*8* `long` or *16* `int`).

When we have an array of references to the instance of the `ğŸ”´ Integer` which are going to hold the values:

* In one read operation we are only going to *transfer the references to this object*.
* And then to get all the values it may be *several read* to maximum *16* reads.

IMPORTANT: This is called **Pointer Chasing** which you need to avoid. To get all the values, we have to *follow pointers* to other places in the memory which has a cost due to the way that data is transferred from the main memory to the cache of the CPU.

Iterating on a `ğŸŸ¢ LinkedList` will imply *much more Pointer Chasing* than iterating on an `ğŸŸ¢ ArrayList`. `ğŸŸ¢ LinkedList` does not store references to the `ğŸ”´ Integer` in an array. It stores them in *a linked list of node objects*. So first, you need to get the first reference to the first node object, and then you need to *follow two pointers*: the first one to the next node object and the second one to the `ğŸ”´ Integer` itself.

Cache Miss::
Whenever the core of a CPU needs a value and that value turns out not to be in the cache. During the Cache Miss, if the value is not in the L2 cache or L3 cache, then the CPU may decide to *suspend the thread* that is executing this computation and *replace it by another thread*. This is a *much bigger performance hit* than just Pointer Chasing, but it is still a consequence of Pointer Chasing.

NOTE: This is why `ğŸŸ¢ LinkedList` is called *cache-unfriendly structure*, whereas `ğŸŸ¢ ArrayList` is called *cache-friendly structure*.

== Fork/Join Framework implementation of parallel `âšª Stream<T>`

NOTE: Fork/Join Framework has been *introduced in Java 7* and *slightly modified in Java 8*.

Going parallel means that this task is going to be *split into subtasks* and each subtask is going to *produce a partial result* (fork step). When those partial results have been computed, they are going to be *sent back to the main task* that has the responsibility of *joining them* (join step).

All those tasks are *sent to a special pool of thread* called *Fork/Join Pool* and this pool has special capabilities to enable the computations of those *subtasks in parallel*.

Fork/Join Framework decides whether the task is *too big and should be split*, or *small enough and should be computed*.

Fork/Join Pool::
Is a pool of threads, instance of the https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/ForkJoinPool.html[`ğŸŸ¢ ForkJoinPool`^]
* created when *the JVM is created*
* there is *only one common* `ğŸŸ¢ ForkJoinPool` in the JVM since Java 8
* it is used for *all* the parallel streams
* the size is *fixed by the number of virtual cores* (not necessarily a good thing) and can be changed with `java.util.concurrent.ForkJoinPool.common.parallelism` system property

Suppose we have a common Fork/Join Pool with *2* threads in it. Each thread is also associated with a waiting queue that can accept tasks. Suppose we have a task to compute:

. The first step is to split this task (_A_) into subtasks (_A11_, _A12_).
. Since parent task (_A_) is waiting for the partial results computed by its subtasks, it will be *put at the end of the waiting queue* thus freeing the first thread 1ï¸âƒ£ that is going to be able to handle the task _A11_.
. Since second thread 2ï¸âƒ£ is not working, it is able to *steal some tasks from another waiting queue*. So second thread 2ï¸âƒ£ will steal a task _A12_ from first thread 1ï¸âƒ£, that is busy with _A11_ task. *All threads will be busy*.
+
NOTE: Fork/Join Framework implements a trick that is quite classical in concurrent programming that is called *work stealing*.
. Once all subtasks will finish computation, the results will be passed to _A_ task which will *apply the reduce operator*.

You need to bench your own computation to be able to tell where your *sweet spot* is going to be in your use case. E.g. computing the sum of 10 integers in array is *much faster sequentially than in parallel*, however computing the sum of several millions integers in array will be *much faster in parallel*.

CAUTION: You also need to check that on a machine that is *as close as possible* to your production machine.

Synchronization::
A feature within the Java language which *prevents two threads from executing the same piece of code*.

In the Stream API there are operations (intermediate and terminal) that need to exchange data or exchange information with the other threads and perform *hidden synchronization* which is a *bottleneck*, e.g. https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html#findFirst()[`âšª Stream<T>#findFirst()`^] (https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html#findAny()[`âšª Stream<T>#findAny()`^] will provide you much better performance in parallel) and https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html#limit(long)[`âšª Stream<T>#limit(long maxSize)`] methods.

If your https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/function/BinaryOperator.html[`âšª BinaryOperator<T>`] from https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/Stream.html#reduce(java.util.function.BinaryOperator)[`âšª Stream<T>#reduce`^] method is *not associative*, then you are going to *compute wrong results* in both: sequential and parallel computing. In parallel, you can also get *different results* each time.

Associative::
Means that first computation gives out the same result as the second computation. Example:
+
[,java]
----
stream.reduce(0, (i1, i2) -> i1*i1 + i2*i2); <1> <2> <3>
----
<1> Given: `[1, 1, 1, 1]`
<2> It should return `4`
<3> Since it is not associative `âšª BinaryOperator<T>`, it will compute `2` (`1`\+`1`), then `5` (`4`+`1`), and it will return `26` (`25`+`1`)

You can display the thread executing your parallel stream with:

[,java]
----
Set<String> threadNames = ConcurrentHashMap.newKeySet();
stream.parallel()
    .(...)
    .peek(i -> threadNames.add(Thread.currentThread().getName()))
    .(...);
threadNames.forEach(System.out::println);
----

You can execute a parallel stream in a custom `ğŸŸ¢ ForkJoinPool`, display the threads executing your parallel stream and count the number of tasks each thread executed with:

[,java]
----
Map<String, Long> threadMap = new ConcurrentHashMap<>();
Callable<Integer> task = () -> {
    int result = stream.parallel()
        .(...)
        .peek(i -> threadMap.merge(Thread.currentThread().getName(), 1L, Long::sum))
        .(...);
    return result;
};

ForkJoinPool forkJoinPool = new ForkJoinPool(4); // <1>
ForkJoinTask<Integer> submit = forkJoinPool.submit(task);
submit.get();
threadMap.forEach((name, n) -> System.out.println(name + " -> " + n));
forkJoinPool.shutdown();
----
<1> Custom `ğŸŸ¢ ForkJoinPool` with 4 threads

== Choosing the right sources of data to efficiently go parallel

The Fork step in Fork/Join Framework works best based on two assumptions:

* The number of elements is *known before processing them*. These sources of data do not meet this condition:
** https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/Iterator.html[`âšª Iterator<E>`]
** https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/regex/Pattern.html[`ğŸ”´ Pattern`^]
** Lines of a text file
* Reaching the *center of the data* must be *easy, reliable and efficient*. This source of data does not meet this condition:
** `ğŸŸ¢ LinkedList`

Fork/Join Framework splits the array in two pieces and *doesn't know* if there is *the same amount of data* in the first half and in the second half. This information is not available, *unless you count all the elements*, one by one, in each half. *The Framework doesn't do that*, because it would be too costly.

Those two halves are going to be split again, and again, and again. Some of the segments of this array are going to be empty. Become higher and higher as the number of splitting increases. *This is a problem with `âšª Set<E>`-like structures*.

Sizeable::
The number of elements of the source is known. All the collections and the arrays are sizeable, but all the patterns, lines and iterators are not sizeable.
Subsizeable::
The number of elements in both parts of a split source is known. Sets are sizeable, but they are not subsizeable.

Processing data from a `âšª List<E>` is *much faster* than the processing data from a `âšª Set<E>` because iterating over the elements of a `âšª List<E>` is faster than iterating over the elements of a `âšª Set<E>`.

TIP: Going parallel as a `âšª List<E>` will bring you *more performance gain* than going parallel in a `âšª Set<E>`.

You may have data to process that, in fact, is *not well spread* over all the *buckets of the array* that is backing your `âšª Set<E>` (e.g. lines of strings that all return 0 hash code will be handled by *only one thread*).

[WARNING]
====
Are you sure that your threads should be used to compute your streams in parallel?::
In case of a web application your threads are used to serve your HTTP clients, so *you don't want those threads to be used for anything else*, including parallel streams. The same goes for threads that are used for SQL transactions. *Threads are precious resources*.
====
